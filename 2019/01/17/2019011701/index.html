<!DOCTYPE HTML>
<html class="no-js" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
    <!--[if lte IE 9]>
<meta http-equiv="refresh" content="0;url=http://yoursite.com/warn.html">
<![endif]-->
<meta charset="utf-8">
<meta http-equiv="X-DNS-Prefetch-Control" content="on">
<link rel="dns-prefetch" href="http://yoursite.com">
<link rel="dns-prefetch" href="//www.google-analytics.com">
<link rel="prefetch" href="http://yoursite.com">
<link rel="prefetch" href="//www.google-analytics.com">


<link rel="prerender" href="http://yoursite.com">

<meta http-equiv="X-UA-Compatible" content="IE=Edge">
<meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width, initial-scale=1.0,user-scalable=no">
<meta http-equiv="mobile-agent" content="format=html5; url=http://yoursite.com">
<meta name="author" content="张萌">
<link rel="stylesheet" href="/css/JSimple.css">

<link rel="shortcut icon" href="/images/favicon.png">


<title>policy gradients - ZhangM</title>

<meta name="keywords" content="教程">

<meta name="description " content="张小姐的个人博客，主要内容是编程，个人学习记录">

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                processEscapes: true
            }
        });
    </script>


    

    

</head>
<body>
<div id="nav">
    <nav class="nav-menu">
        <a class="site-name current" href="/" title="萌">萌</a>
        <a class="site-index current" href="/"><i class="fa fa-home"></i><span>首页</span></a>
        <a href="/archives" title="归档"><i class="fa fa-archives"></i><span>归档</span></a>
        <a href="/tags" title="标签"><i class="fa fa-tags"></i><span>标签</span></a>
        <!-- custom single page of menus -->
        
        
        <a href="/about" title="关于">
            <i class="fa fa-question-circle"></i>
            <span>关于</span>
        </a>
        
    </nav>
</div>

<div class="nav-user">
    <a class="btn-search" href="#"><i class="fa fa-search"></i></a>
    <a class="btn-read-mode" href="#"><i class="fa fa-sun-o"></i></a>
    <a class="btn-sns-qr" href="javascript:"><i class="fa fa-telegram"></i></a>
</div>

<div id="wrapper" class="clearfix">
    <div id="body">
        <div class="main" id="main">
            <div id="cover">
    <div class="cover-img"></div>
    <div class="cover-info">
        
        <h1 class="cover-siteName">小努力</h1>
        <h3 class="cover-siteTitle">瞎搞罢了</h3>
        <p class="cover-siteDesc">一个菜鸟的IT博客</p>
        <div class="cover-sns">
            

        </div>
    </div>
</div>

            <div class="page-title">
    <ul>
        <li><a href="/">最近</a></li>
        
            
                <li class="">
                    <a href="/categories/leetcode" data-name="LeetCode">LeetCode</a>
                </li>
            
                <li class="">
                    <a href="/categories/Unity" data-name="Unity">Unity</a>
                </li>
            
                <li class="">
                    <a href="/categories/c,hololens,tensorflow,reinforcement-learning" data-name="其他">其他</a>
                </li>
            
        
        <li class="page-search">
    <form id="search" class="search-form">
        <input type="text" readonly="readonly" id="local-search-input-tip" placeholder="读物检索~">
        <button type="button" disabled="disabled" class="search-form-submit"><i class="fa fa-search"></i></button>
    </form>
</li>

    </ul>
</div>
<div class="main-inner">
    <article class="post" itemscope="" itemtype="http://schema.org/BlogPosting">
        <div class="post-header">
            <div class="post-author clearfix">
                <a class="avatar fleft" href="https://zhangmeng.ga/" target="_blank">
                    <img width="48" src="/images/favicon.png" alt="avatar">
                </a>
                <p><span class="label">作者</span>
                    <a href="https://zhangmeng.ga/" target="_blank">张萌</a>
                    <span title="最后编辑于&nbsp;2019-01-17">2019-01-17</span>
                </p>
                <p>十分平凡可爱非常。</p>
            </div>
            <h2 class="post-title">Policy Gradients</h2>
            <div class="post-meta">
                本文共计2024个字 |
                您是第&nbsp;<span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span>位看到它们的小伙伴
            </div>
        </div>
        <div class="post-content markdown-body">
            <p>策略梯度</p>
<a id="more"></a>
<p>强化学习是一个通过奖惩来学习正确行为的机制. 家族中有很多种不一样的成员, 有学习奖惩值, 根据自己认为的高价值选行为, 比如 Q learning, Deep Q Network, 也有不通过分析奖励值, 直接输出行为的方法, 这就是今天要说的 Policy Gradients 了. </p>
<p>Policy gradient 是 RL 中另外一个大家族, 他借用神经网络，在无穷多的动作中计算价值, 从而选择行为。不像 Value-based 方法 (Q learning, Sarsa), 他也要接受环境信息 (observation), 不同的是他<strong>要输出不是 action 的 value, 而是具体的那一个 action</strong>, 这样 policy gradient 就跳过了 value 这个阶段. 而且个人认为 Policy gradient 最大的一个优势是: 输出的这个 action 可以是一个连续的值, 之前我们说到的 value-based 方法输出的都是不连续的值, 然后再选择值最大的 action. 而 policy gradient 可以在一个连续分布上选取 action.</p>
<h3><span id="算法">算法</span></h3><p><img src="2019011701\2159902-13d5d1a3acbf2157.png" alt=""></p>
<p>在深度强化学习中，<strong>Policy Π 可以看做是一个参数为 θ 的神经网络</strong>，输入当前的state，输出可能的action的概率分布，选择概率最大的一个action作为要执行的操作。</p>
<p>Policy Gradient不通过误差反向传播，它通过观测信息选出一个行为直接进行反向传播，当然出人意料的是他并没有误差，而是利用reward奖励直接对选择行为的可能性进行增强和减弱，好的行为会被增加下一次被选中的概率，不好的行为会被减弱下次被选中的概率。</p>
<p>以游戏为例，从游戏开始到结束，叫做一个episode，简单理解为回合。episode结束，游戏过程中所有的reward相加得到该回合的总reward（角色挂与未挂可能是一个负reward或一个大的正reward）。</p>
<p><img src="D:\hexo\web2\source\_posts\2019011701\2159902-ddae732feac73216.png" alt=""></p>
<p>这里强化学习的目标就是学习一个Policy，即一个网络，使其每看到一个画面，做出一个action, 并做到最终获得最大总reward。</p>
<h4><span id="算法细节">算法细节</span></h4><p>游戏的进程相应的可以表示成state,action交替的序列：</p>
<p><img src="2019011701\2159902-2083b56a56aada88.png" alt=""></p>
<p>游戏引擎（Environment）产生一个画面（state）,接着神经网络玩家（Actor）产生一个action，接着影响Environment，并产生下一个state，如此反复到游戏结束，一个完整的序列（1-T）为一个Trajectory，一轮游戏一轮回合，或者叫一轮采样。该序列发生的概率，即在策略Π 的参数为θ 情况下Trajectory τ发生的概率：</p>
<p><img src="2019011701\2159902-4ddd6fd020512976.png" alt=""></p>
<p>这样在此Trajectory下会得到一个总的回报R(τ)，可以想到，玩游戏有很大的随机性，不同的action就可能会有不同的state，反之亦然。因此R(τ)实际是一个变量（根据游戏场景过程的变化而变化），因此为了衡量一个策略Π的好坏，需要考虑一个期望的回报R_E(τ)。游戏的过程当然也不可能穷举，因此就需要采样来计算期望回报（“平均”回报），可以理解为Policy固定情况下反复的试玩N回合游戏，每回合的reward<strong><em>以回合发生概率为权重相加取平均</em></strong>，即为当前策略的期望reward。目标也就是<strong><em>不断更新Policy的参数θ，使期望reward得到最大</em></strong>。<em>**</em></p>
<p><img src="2019011701\2159902-9f56dcfcdca9ffca.png" alt=""></p>
<h4><span id="策略梯度提升">策略梯度提升</span></h4><p>有了目标，下面就是用合适的方法，使期望reward最大，一种方法便是策略梯度提升的方法（与最小化loss的梯度下降相对）。由上面可知期望reward是参数θ的函数，所以参数更新的方式为：</p>
<p><img src="2019011701\2159902-aea1a369ca61875b.png" alt=""></p>
<p>下面的问题就是期望reward对θ的导数的求法，走一波公式推导：</p>
<p><img src="2019011701\2159902-0e5293f2a59fb71f.png" alt=""></p>
<p>公式推导并不复杂，主要是蓝框里的一个常用小技巧变换（同时乘和除f(x)）。然后第二行等式到第三行将累加转换为期望表示；接着约等于N次采样的期望值。第三行到第四行将上面的p_{θ}(τ)带入，去掉与θ无关的环境相关概率p(s_{t+1}|s_t, a_t)和p(s_1),得到最终结果：</p>
<p><img src="2019011701\2159902-666c1f7037af194e.png" alt=""></p>
<p>下面就是不断采样，更新参数的过程（根据当前策略玩游戏，得回报，修正策略）：</p>
<p><img src="2019011701\2159902-8a275b32e2655751.png" alt=""></p>
<p>图示左边表示根据当前policy参数采样得到N个Trajectory，计算一次期望reward，然后梯度上升的方法更新policy参数，用更新后的policy再进行下一轮采样，如此往复直到收敛，得到期望reward最大的policy。最终该policy（神经网络表示）就学会了根据游戏画面做合适的action，最终赢得游戏。</p>
<h5><span id="优点">优点：</span></h5><ul>
<li>连续的动作空间（或者高维空间）中更加高效；</li>
<li>可以实现随机化的策略；</li>
<li>某种情况下，价值函数可能比较难以计算，而策略函数较容易。</li>
</ul>
<h5><span id="缺点">缺点：</span></h5><ul>
<li>通常收敛到局部最优而非全局最优</li>
<li>评估一个策略通常低效（这个过程可能慢，但是具有更高的可变性，其中也会出现很多并不有效的尝试，而且方差高</li>
</ul>

        </div>
        <div class="post-tool">
            <a class="btn-thumbs-up" href="javascript:void(0);" data-cid="52" title="95">
                <i class="fa fa-thumbs-up" aria-hidden="true"></i> 打赏
            </a>
        </div>
        
        <div class="post-tags">标签：
            
            <a href="/tags/reinforcement-learning/">reinforcement learning</a>
            
        </div>
        
    </article>
    
    <p style="text-align: center">本文代表个人观点，内容仅供参考。若有不恰当之处，望不吝赐教！</p>
    
    

    

</div>
<script src="/js/busuanzi.pure.mini.js"></script>


        </div><!-- end #main-->
    </div><!-- end #body -->
    <footer class="footer">
    <div class="footer-inner" style="text-align: center">
        <p>
            <a href="/about" title="关于">关于</a>&nbsp;&nbsp<em>·</em>&nbsp;&nbsp
            <!-- 自定义链接 -->
            <a href="/help" title="帮助">帮助</a>&nbsp;&nbsp<em>·</em>&nbsp;&nbsp
            <a href="/links" title="友链">友链</a>&nbsp;&nbsp<em>·</em>&nbsp;&nbsp
            <a href="/sitemap.xml" title="地图">地图</a>
        </p>
        <p>
            本站已建立&nbsp<a href="/timeline" id="siteBuildingTime"></a>&nbsp天，<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="licence">采用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议创作</a><br>
            ©2017-<span id="cpYear"></span> 基于&nbsp<a href="http://hexo.io" target="_blank" rel="nofollow">Hexo</a>
            ，主题采用&nbsp&nbsp<a href="https://github.com/tangkunyin/hexo-theme-jsimple" target="_blank" rel="bookmark">JSimple</a>
            ，作者&nbsp<a href="https://zhangmeng.ga/" target="_blank" rel="friend">张萌</a>
            ，Hosted by <a href="https://pages.github.com/" target="_blank" rel="nofollow">GitHub Pages</a>
        </p>
    </div>
</footer>
<script src="/js/SimpleCore.js"></script>

</div>
<!-- search pop -->
<div class="popup search-popup local-search-popup">
    <div class="local-search-header clearfix">
        <span class="search-icon">
            <i class="fa fa-search"></i>
        </span>
        <span class="popup-btn-close">
            <i class="fa fa-times-circle"></i>
        </span>
        <div class="local-search-input-wrapper">
            <input id="local-search-input" spellcheck="false" type="text" autocomplete="off" placeholder="请输入查询关键词">
        </div>
    </div>
    <div id="local-search-result"></div>
</div>
<div class="fixed-btn">
    <a class="btn-gotop" href="javascript:"> <i class="fa fa-angle-up"></i></a>
</div>
<script>
    $(function () {
        var jsi_config = {
            buildingTime: '01/10/2019',
            current: $('.post-tags').length > 0 ? 'post' : 'archive',
            snsQRCode: '/images/sns-qrcode.png',
            donateImg: '/images/donate-qr.png',
            localSearch: { dbPath: '' },
            readMode: 'day'
        };
        
            jsi_config.localSearch = {
                dbPath: '/search.json',
                trigger: 'auto',
                topN: '1',
                unescape: 'false'
            }
        
        SimpleCore.init(jsi_config);
        
    });
</script>
</body>
</html>
